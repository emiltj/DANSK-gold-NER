{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first ent in the doc is of type: \n",
      "<class 'spacy.tokens.span.Span'>\n",
      "\n",
      "The first element in the doc is of type: \n",
      "<class 'spacy.tokens.token.Token'>\n",
      "\n",
      "The spans in the doc are: \n",
      "{}\n",
      "\n",
      "The first element in the doc (token), attribute: .ent_type_: \n",
      "GPE\n",
      "\n",
      "The first element in doc.ents, attribute: .label_: \n",
      "GPE\n",
      "\n",
      "\n",
      "1: GPE\n",
      "2: GPE\n",
      "3: GPE\n",
      "4: LOC\n",
      "5: LOC\n"
     ]
    }
   ],
   "source": [
    "text = \"Denmark is a Nordic country\"\n",
    "doc = nlp(text)\n",
    "\n",
    "print(f'The first ent in the doc is of type: \\n{type(doc.ents[0])}')\n",
    "print(f'\\nThe first element in the doc is of type: \\n{type(doc[0])}')\n",
    "print(f'\\nThe spans in the doc are: \\n{doc.spans}')\n",
    "print(f'\\nThe first element in the doc (token), attribute: .ent_type_: \\n{doc[0].ent_type_}')\n",
    "print(f'\\nThe first element in doc.ents, attribute: .label_: \\n{doc.ents[0].label_}\\n\\n')\n",
    "\n",
    "\n",
    "print(f'1: {doc.ents[0].label_}')\n",
    "doc.ents[0].label_ = 'LOC'\n",
    "print(f'2: {doc.ents[0].label_}')\n",
    "\n",
    "print(f'3: {doc[0].ent_type_}')\n",
    "doc[0].ent_type_ = 'LOC'\n",
    "print(f'4: {doc[0].ent_type_}')\n",
    "\n",
    "print(f'5: {doc.ents[0].label_}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3].ent_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ents = [Span(doc, 0, 1, 385)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Denmark,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[3].ent_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "437\n",
      "2842\n",
      "3279\n",
      "3264\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd    \n",
    "jsonObj = pd.read_json(path_or_buf='./data/prodigy_exports/prodigy1_db_exports/NER_interannotator_annotator1.jsonl', lines=True)\n",
    "jsonObj2 = pd.read_json(path_or_buf='./data/prodigy_exports/prodigy1_db_exports/NER_annotator1.jsonl', lines=True)\n",
    "unique_docs_interannotator = list(set(list(jsonObj['text'])))\n",
    "unique_docs_annotator = list(set(list(jsonObj2['text'])))\n",
    "with_potential_duplicates = (unique_docs_interannotator + unique_docs_annotator)\n",
    "without_potential_duplicates = set(unique_docs_interannotator + unique_docs_annotator)\n",
    "n_duplicates = len(with_potential_duplicates) - len(without_potential_duplicates)\n",
    "\n",
    "print(f'n_docs in interannotator data: {len(unique_docs_interannotator)}')\n",
    "print(f'n_docs in annotator data: {len(unique_docs_annotator)}')\n",
    "print(f'n_docs in combined (with potential duplicates): {len(with_potential_duplicates)}')\n",
    "print(f'n_docs in combined (without duplicates): {len(without_potential_duplicates)}')\n",
    "print(f'n_duplicates in combined: {n_duplicates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset ontonotes5 (/Users/emiltrencknerjessen/.cache/huggingface/datasets/tner___ontonotes5/ontonotes5/1.0.0/58d8410f24e689c113094eef1d1686365ba9155c66b57bdf8fa4273307c37612)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"tner/ontonotes5\", split = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['``', 'A', 'great', 'many', 'federal', 'regulations', 'are', 'meant', 'for', 'larger', 'entities', 'and', 'do', \"n't\", 'really', 'apply', 'to', 'small', 'businesses', ',', \"''\", 'says', 'Marian', 'Jacob', ',', 'a', 'legislative', 'aide', 'to', 'Sen.', 'Wallop', '.']\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 5, 0, 0, 0, 0, 0, 0, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "print(dataset[7]['tokens'])\n",
    "print(dataset[7]['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = dataset.features[\"tags\"]\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f092f9808d781aed1cffbee1778720285e402013b75f9f1b9e21e42cac7a28f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
