{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy, os\n",
    "import spacy_wrap\n",
    "import srsly\n",
    "import re\n",
    "import copy\n",
    "from prodigy.components.db import connect\n",
    "from spacy.tokens import DocBin\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "# Load gold-full data as doc objects\n",
    "db = DocBin()\n",
    "full = db.from_disk(\"../../data/full/gold/gold-full.spacy\")\n",
    "nlp = spacy.blank(\"da\")\n",
    "docs = list(full.get_docs(nlp.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "449\n"
     ]
    }
   ],
   "source": [
    "\n",
    "review_docs_idxs = []\n",
    "for i, doc in enumerate(docs):\n",
    "    # If doc contains string matching TIME spans\n",
    "    if re.search(\"\\d{1,2}:\\d\\d ?[-|\\||\\/] ?\\d\", doc.text) or re.search(\n",
    "        \"dag: \\d{1,2}\", doc.text\n",
    "    ):\n",
    "        review_docs_idxs.append(i)\n",
    "        \n",
    "    # If doc contains string matching DATE spans:\n",
    "    if re.search(\"\\d{2,4} ?[-|–] ?\\d{2,4}\", doc.text):\n",
    "        review_docs_idxs.append(i)\n",
    "        \n",
    "    # If doc contains string matching A/S og ApS\n",
    "    if re.search(\"ApS\", doc.text) or re.search(\"A\\/S\", doc.text):\n",
    "        review_docs_idxs.append(i)\n",
    "        \n",
    "    # If doc contains a number written with letters and it is not included as a ent already\n",
    "    if re.search(\" to | to$|^to| To | To$|^To| TO | TO$|^TO| tre | tre$|^tre| Tre | Tre$|^Tre| TRE | TRE$|^TRE| fire | fire$|^fire| Fire | Fire$|^Fire| FIRE | FIRE$|^FIRE| fem | fem$|^fem| Fem | Fem$|^Fem| FEM | FEM$|^FEM| seks | seks$|^seks| Seks | Seks$|^Seks| SEKS | SEKS$|^SYV| otte | otte$|^otte| Otte | Otte$|^Otte| OTTE | OTTE$|^OTTE| ni | ni$|^ni| Ni | Ni$|^Ni| NI | NI$|^NI| ti | ti$|^ti| Ti | Ti$|^Ti| TI | TI$|^TI\", ent.text):\n",
    "        ents_string = \" \".join([str(ent) for ent in list(doc.ents)])\n",
    "        if re.search(\" to | to$|^to| To | To$|^To| TO | TO$|^TO| tre | tre$|^tre| Tre | Tre$|^Tre| TRE | TRE$|^TRE| fire | fire$|^fire| Fire | Fire$|^Fire| FIRE | FIRE$|^FIRE| fem | fem$|^fem| Fem | Fem$|^Fem| FEM | FEM$|^FEM| seks | seks$|^seks| Seks | Seks$|^Seks| SEKS | SEKS$|^SYV| otte | otte$|^otte| Otte | Otte$|^Otte| OTTE | OTTE$|^OTTE| ni | ni$|^ni| Ni | Ni$|^Ni| NI | NI$|^NI| ti | ti$|^ti| Ti | Ti$|^Ti| TI | TI$|^TI\", ents_string):\n",
    "            review_docs_idxs.append(i)\n",
    "        \n",
    "    for ent in doc.ents:\n",
    "        # Dates with \"Den\" or similar\n",
    "        if ent.label_ == \"DATE\" and re.search(\"^d.{0,2} \\d\", ent.text):\n",
    "            review_docs_idxs.append(i)\n",
    "        \n",
    "        # Himlen as LOCATION:\n",
    "        if ent.label_ == \"LOCATION\" and re.search(\"[Hh][iI][mM][lL][Ee][Nn]|[Hh][iI][mM][mM][Ee][lL][Ee][Nn]\", ent.text):\n",
    "            review_docs_idxs.append(i)\n",
    "        \n",
    "        # Gud as PERSON:\n",
    "        if ent.label_ == \"PERSON\" and re.search(\"[Gg][Uu][Dd]\", ent.text):\n",
    "            review_docs_idxs.append(i)\n",
    "        \n",
    "        # Adresses as GPE:\n",
    "        if ent.label_ == \"GPE\" and re.search(\".*\\d ?\", ent.text):\n",
    "            review_docs_idxs.append(i)\n",
    "            \n",
    "        # Telephone numbers wrongly tagged as Cardinal\n",
    "        if ent.label_ == \"CARDINAL\" and (\n",
    "            re.search(\n",
    "                \"\\d{2} \\d{2} \\d{2} \\d{2}\",\n",
    "                ent.text\n",
    "                or re.search(\"\\+\\d{2} \\d{2} ?\\d{2} ?\\d{2} ?\\d{2}$\", ent.text)\n",
    "                or re.search(\"^\\d{4} ?\\d{4}$\", ent.text)\n",
    "                or re.search(\" \\d{4} ?\\d{4}$\", ent.text)\n",
    "                or re.search(\"^\\d{4} ?\\d{4}$\", ent.text),\n",
    "            )\n",
    "        ):\n",
    "            review_docs_idxs.append(i)\n",
    "            \n",
    "        # Websites wrongly tagged as ORGANIZATIONS:\n",
    "        if ent.label_ == \"ORGANIZATION\" and re.search(\".dk$|.com$\", ent.text):\n",
    "            review_docs_idxs.append(i)\n",
    "            \n",
    "        # Hotels and resorts wrongly tagged as ORGANIZATION:\n",
    "        if ent.label_ == \"ORGANIZATION\" and re.search(\n",
    "            \".*[h|H]otel.*|.*[R|r]esort.*\", ent.text\n",
    "        ):\n",
    "            review_docs_idxs.append(i)\n",
    "            \n",
    "        # Numbers with / or :, wrongly tagged as CARDINAL:\n",
    "        if ent.label_ == \"CARDINAL\" and (\n",
    "            re.search(\"\\/\", ent.text)\n",
    "            or re.search(\"\\:\", ent.text)\n",
    "            or re.search(\" \", ent.text)\n",
    "            or re.search(\"-\", ent.text)\n",
    "        ):\n",
    "            review_docs_idxs.append(i)\n",
    "            \n",
    "        # Fortrydelsesret, Ophavsret, Ytringsfrihed, Menneskerettigheder, Copyright, Returret wrongly tagged as LAWS\n",
    "        if ent.label_ == \"LAW\" and (\n",
    "            re.search(\n",
    "                \"[C|c]opyright\",\n",
    "                ent.text\n",
    "                or re.search(\"[®|©]\", ent.text)\n",
    "                or re.search(\"[R|r]eturret\", ent.text)\n",
    "                or re.search(\"[f|F]ortrydelsesret\", ent.text)\n",
    "                or re.search(\"[o|O]phavsret$\", ent.text)\n",
    "                or re.search(\"enneskeret\", ent.text),\n",
    "            )\n",
    "        ):\n",
    "            review_docs_idxs.append(i)\n",
    "            \n",
    "\n",
    "review_docs_idxs = list(set(review_docs_idxs))\n",
    "print(len(review_docs_idxs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_docs = [docs[idx] for idx in review_docs_idxs]\n",
    "\n",
    "good_docs = copy.deepcopy(docs)\n",
    "\n",
    "review_docs_idxs.sort(reverse=True)\n",
    "for idx in review_docs_idxs:\n",
    "    del good_docs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "db1 = DocBin(store_user_data=True)\n",
    "for doc in bad_docs:\n",
    "    db1.add(doc)\n",
    "db1.to_disk(\"../../data/full/gold/gold-bad.spacy\")\n",
    "\n",
    "db2 = DocBin(store_user_data=True)\n",
    "for doc in good_docs:\n",
    "    db2.add(doc)\n",
    "db2.to_disk(\"../../data/full/gold/gold-good.spacy\")\n",
    "\n",
    "# Extra just for being able to review against something:\n",
    "db3 = DocBin(store_user_data=True)\n",
    "for doc in bad_docs:\n",
    "    doc.ents = ()\n",
    "    db3.add(doc)\n",
    "db3.to_disk(\"../../data/full/gold/gold-bad-no-tags.spacy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0f092f9808d781aed1cffbee1778720285e402013b75f9f1b9e21e42cac7a28f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
